import streamlit as st
import requests
import base64
from typing import Dict
import io
from PIL import Image
import os
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# ä»Streamlit Secretsè·å–å‡­è¯
account_id = st.secrets.get("CLOUDFLARE_ACCOUNT_ID", "")
api_token = st.secrets.get("CLOUDFLARE_API_TOKEN", "")

class MultiModelGenerator:
    def __init__(self, account_id: str, api_token: str):
        self.account_id = account_id
        self.api_token = api_token
        
        # å®šä¹‰æ‰€æœ‰æ”¯æŒçš„AIæ¨¡å‹
        self.models = [
            {
                "id": "@cf/stabilityai/stable-diffusion-xl-base-1.0",
                "name": "SDXL Base",
                "description": "æœ€é«˜è´¨é‡çš„SDXLåŸºç¡€ç‰ˆæœ¬",
                "steps": None
            },
            {
                "id": "@cf/bytedance/stable-diffusion-xl-lightning",
                "name": "SDXL Lightning",
                "description": "å­—èŠ‚ä¼˜åŒ–çš„å¿«é€ŸSDXLç‰ˆæœ¬",
                "steps": None
            },
            {
                "id": "@cf/lykon/dreamshaper-8-lcm",
                "name": "Dreamshaper",
                "description": "å¿«é€Ÿçš„Dreamshaperæ¨¡å‹",
                "steps": 8
            },
            {
                "id": "@cf/black-forest-labs/flux-1-schnell",
                "name": "Flux Schnell",
                "description": "è½»é‡å¿«é€Ÿç”Ÿæˆæ¨¡å‹",
                "steps": 8
            }
        ]
        
        # å®šä¹‰æ”¯æŒçš„å›¾åƒå°ºå¯¸
        self.sizes = [
            {"id": "1024x1024", "name": "1:1 æ–¹å½¢ (1024x1024)"},
            {"id": "1024x576", "name": "16:9 æ¨ªå‘ (1024x576)"},
            {"id": "576x1024", "name": "9:16 çºµå‘ (576x1024)"}
        ]
        
        # å®šä¹‰ä¸»é¢˜æ¨¡æ¿
        self.themes = [
            "a beautiful girl",
            "a handsome man", 
            "a future city",
            "a fantasy landscape", 
            "a cyberpunk scene", 
            "an ancient castle"
        ]

    async def generate_image_async(self, session, model: Dict, prompt: str, size: str) -> tuple:
        """å¼‚æ­¥ç”Ÿæˆå›¾åƒ"""
        width, height = map(int, size.split('x'))
        url = f"https://api.cloudflare.com/client/v4/accounts/{self.account_id}/ai/run/{model['id']}"
        
        headers = {
            "Authorization": f"Bearer {self.api_token}",
            "Content-Type": "application/json"
        }
        
        params = {
            "prompt": prompt,
            "width": width,
            "height": height
        }
        
        # æ·»åŠ stepså‚æ•°ï¼ˆå¦‚æœæ¨¡å‹éœ€è¦ï¼‰
        if model['steps']:
            params["steps"] = model['steps']
        
        try:
            async with session.post(url, headers=headers, json=params) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"APIé”™è¯¯: {error_text}")
                
                content_type = response.headers.get('content-type', '')
                
                if 'application/json' in content_type:
                    result = await response.json()
                    if model['id'] == "@cf/black-forest-labs/flux-1-schnell":
                        if 'result' in result and isinstance(result['result'], dict) and 'image' in result['result']:
                            image_data = base64.b64decode(result['result']['image'])
                        else:
                            raise Exception("Fluxæ¨¡å‹è¿”å›äº†æ„å¤–çš„JSONæ ¼å¼")
                    else:
                        if 'error' in result:
                            raise Exception(f"APIé”™è¯¯: {result['error']}")
                        image_data = await response.read()
                else:
                    image_data = await response.read()
                
                image = Image.open(io.BytesIO(image_data))
                return model['id'], image
                
        except Exception as e:
            return model['id'], e

    def generate_prompt_with_llm(self, theme: str) -> str:
        """ä½¿ç”¨LLMç”Ÿæˆè¯¦ç»†çš„å›¾åƒæç¤ºè¯"""
        system_prompt = """You are an expert at writing Stable Diffusion prompts. Create detailed, artistic prompts for image generation.

Important rules for the prompts:
1. Be VERY detailed and descriptive
2. Include ALL of these aspects:
   - Main subject details
   - Lighting and atmosphere
   - Color palette or mood
   - Camera angle or perspective
   - Artistic style or medium
   - Technical quality terms

Format your prompt like this:
[main subject details], [lighting], [atmosphere], [colors/mood], [camera/perspective], [artistic style], [technical quality]

Examples:
Theme: a beautiful girl
"ethereal young woman with flowing auburn hair and delicate features, soft golden hour sunlight streaming through gossamer curtains, dreamy atmospheric mood, warm pastel color palette, medium close-up shot with shallow depth of field, fashion photography style, cinematic composition, 8k resolution, masterpiece quality, highly detailed"

Theme: a cyberpunk city
"massive cyberpunk metropolis with towering crystalline skyscrapers, neon signs reflecting in rain-slicked streets, volumetric fog catching holographic advertisements, moody night atmosphere with electric blue and purple hues, dramatic low angle view looking up, blade runner style, ray traced lighting, cinematic composition, 8k resolution, masterpiece quality, photorealistic details"
"""

        user_prompt = f"""Create a highly detailed Stable Diffusion prompt for: {theme}
Include specific details about subject, lighting, atmosphere, colors, camera view, and artistic style."""
        
        try:
            url = f"https://api.cloudflare.com/client/v4/accounts/{self.account_id}/ai/run/@cf/deepseek-ai/deepseek-r1-distill-qwen-32b"
            
            headers = {
                "Authorization": f"Bearer {self.api_token}",
                "Content-Type": "application/json"
            }
            
            data = {
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.3,
                "max_tokens": 1000
            }
            
            response = requests.post(url, headers=headers, json=data)
            response.raise_for_status()
            result = response.json()
            
            prompt = result['result']['response'].strip()
            prompt = prompt.replace('PROMPT:', '').replace('think', '')
            prompt = prompt.replace('<', '').replace('>', '')
            prompt = prompt.split('\n')[0].strip()
            
            if not any(term in prompt.lower() for term in ['8k', 'masterpiece', 'highly detailed']):
                prompt = f"{prompt}, 8k, masterpiece, highly detailed"
            
            return prompt
            
        except Exception as e:
            st.error(f"ç”Ÿæˆæç¤ºè¯å¤±è´¥: {e}")
            return f"{theme}, cinematic lighting, highly detailed, 8k"

async def main():
    st.set_page_config(
        page_title="AIå›¾åƒç”Ÿæˆå™¨ V2",
        page_icon="ğŸ¨",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ¨ AIå›¾åƒç”Ÿæˆå™¨ V2")
    st.markdown("### ä½¿ç”¨å¤šä¸ªCloudflare AIæ¨¡å‹åŒæ—¶ç”Ÿæˆå›¾åƒï¼Œå¯¹æ¯”ä¸åŒæ¨¡å‹çš„æ•ˆæœ")
    
    if not account_id or not api_token:
        st.error("è¯·è®¾ç½®Cloudflareå‡­è¯ï¼")
        st.stop()
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = MultiModelGenerator(account_id=account_id, api_token=api_token)
    
    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.header("ğŸ› ï¸ è®¾ç½®")
        
        # é€‰æ‹©å›¾åƒå°ºå¯¸
        selected_size = st.selectbox(
            "ğŸ“ é€‰æ‹©å›¾åƒå°ºå¯¸",
            options=generator.sizes,
            format_func=lambda x: x['name']
        )
        
        # é€‰æ‹©æ˜¯å¦ä½¿ç”¨AIç”Ÿæˆæç¤ºè¯
        use_ai_prompt = st.checkbox("ğŸ¤– ä½¿ç”¨AIç”Ÿæˆæç¤ºè¯", value=True)
        
        if use_ai_prompt:
            selected_theme = st.selectbox(
                "ğŸ¯ é€‰æ‹©ä¸»é¢˜",
                options=generator.themes,
                help="é€‰æ‹©ä¸€ä¸ªä¸»é¢˜ï¼ŒAIå°†ä¸ºæ‚¨ç”Ÿæˆè¯¦ç»†çš„å›¾åƒæç¤ºè¯"
            )
            
            if st.button("ğŸ² ç”Ÿæˆæç¤ºè¯", use_container_width=True):
                with st.spinner("ğŸ¤– AIæ­£åœ¨åˆ›ä½œæç¤ºè¯..."):
                    prompt = generator.generate_prompt_with_llm(selected_theme)
                    st.session_state.generated_prompt = prompt
                    st.success("âœ¨ æç¤ºè¯ç”Ÿæˆå®Œæˆï¼")
            
            prompt = st.text_area(
                "âœï¸ AIç”Ÿæˆçš„æç¤ºè¯ (å¯ä»¥ä¿®æ”¹)",
                value=st.session_state.get('generated_prompt', ''),
                height=150,
                help="è¿™æ˜¯AIæ ¹æ®é€‰æ‹©çš„ä¸»é¢˜ç”Ÿæˆçš„è¯¦ç»†æç¤ºè¯ï¼Œæ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨æˆ–è¿›è¡Œä¿®æ”¹"
            )
        else:
            prompt = st.text_area(
                "âœï¸ è¾“å…¥æç¤ºè¯",
                height=150,
                help="æè¿°æ‚¨æƒ³è¦ç”Ÿæˆçš„å›¾åƒï¼Œå¯ä»¥éå¸¸è¯¦ç»†"
            )
        
        generate_button = st.button("ğŸ¨ åŒæ—¶ç”Ÿæˆæ‰€æœ‰å›¾åƒ", type="primary", use_container_width=True)

    # ä¸»è¦å†…å®¹åŒºåŸŸ
    if generate_button and prompt:
        # åˆ›å»º2x2ç½‘æ ¼
        row1_col1, row1_col2 = st.columns(2)
        row2_col1, row2_col2 = st.columns(2)
        
        grid = [
            row1_col1, row1_col2,
            row2_col1, row2_col2
        ]
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºå ä½ç¬¦
        placeholders = {}
        for i, model in enumerate(generator.models):
            with grid[i]:
                st.subheader(f"ğŸ“¸ {model['name']}")
                st.markdown(f"*{model['description']}*")
                placeholders[model['id']] = st.empty()
        
        # å¼‚æ­¥ç”Ÿæˆæ‰€æœ‰å›¾åƒ
        async with aiohttp.ClientSession() as session:
            tasks = []
            for model in generator.models:
                task = generator.generate_image_async(session, model, prompt, selected_size['id'])
                tasks.append(task)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            total_models = len(generator.models)
            completed = 0
            
            for coro in asyncio.as_completed(tasks):
                model_id, result = await coro
                completed += 1
                progress = completed / total_models
                progress_bar.progress(progress)
                status_text.text(f"å·²å®Œæˆ {completed}/{total_models} ä¸ªæ¨¡å‹")
                
                # è·å–å¯¹åº”çš„æ¨¡å‹ä¿¡æ¯
                model = next(m for m in generator.models if m['id'] == model_id)
                
                # æ˜¾ç¤ºç»“æœ
                if isinstance(result, Exception):
                    placeholders[model_id].error(f"âŒ {model['name']} ç”Ÿæˆå¤±è´¥: {str(result)}")
                else:
                    placeholders[model_id].image(
                        result,
                        caption=f"ç”± {model['name']} ç”Ÿæˆ",
                        use_column_width=True
                    )
                    
                    # æä¾›ä¸‹è½½æŒ‰é’®
                    buf = io.BytesIO()
                    result.save(buf, format="PNG")
                    with grid[generator.models.index(model)]:
                        st.download_button(
                            label=f"â¬‡ï¸ ä¸‹è½½ {model['name']} ç”Ÿæˆçš„å›¾åƒ",
                            data=buf.getvalue(),
                            file_name=f"generated_image_{model['name']}.png",
                            mime="image/png",
                            use_container_width=True
                        )
        
        # å®Œæˆåæ¸…é™¤è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬
        progress_bar.empty()
        status_text.empty()
        st.success("ğŸ‰ æ‰€æœ‰å›¾åƒç”Ÿæˆå®Œæˆï¼")
    else:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è®¾ç½®æç¤ºè¯å¹¶ç‚¹å‡»ç”ŸæˆæŒ‰é’®å¼€å§‹åˆ›å»ºå›¾åƒ")

if __name__ == "__main__":
    asyncio.run(main()) 